{"cells":[{"cell_type":"markdown","metadata":{"id":"9R66vy-1Fn5C"},"source":["\n","### <center>Procesamiento Digital de Señales de Audio</center>\n","#### <center>Instituto de Ingeniería Eléctrica - UdelaR</center>\n","# Hoja de Ejercicios 4 - Curso 2024\n","### Análisis homomórfico\n","### Análisis por predicción lineal\n","\n","\n","## Pautas para el práctico\n"," - La realización del presente trabajo es individual.\n"," - Es necesario abordar todos los ejercicios propuestos.\n"," - Se espera la entrega de un PDF escrito en $\\LaTeX$ o similar. El mismo tendrá:\n","     - Máximo de 14 páginas\n","     - Máximo de 2500 palabras\n"," - También se espera la entrega del código escrito, en scripts Python o en este mismo Jupyter Notebook.\n"," - La corrección del práctico se hará sobre lo entregado en el PDF, pero podremos apoyarnos en el razonamiento y comprensión demostrado en el código escrito. Recomendamos escribir el código de forma prolija para facilitar la comprensión presente y futura tanto de nosotros como de ustedes.\n"," - Los ejercicios marcados como $\\blacklozenge$ son opcionales.\n","\n","\n","**Nombre de el/la estudiante:** "]},{"cell_type":"markdown","metadata":{"id":"lW99wQc4_MJh"},"source":["### Como correr este notebook\n","\n","Es posible descargarlo y correrlo localmente en su computadora\n","\n","Tambien pueden correrlo en Google Colab usando el siguiente link.\n","\n","<table align=\"center\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/audio-dsp/blob/main/practicos/AudioDSP_Practico_4.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Correr en Google Colab</a>\n","  </td>\n","</table>"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# # Al correr esta celda, se podrá acceder a archivos\n","# # y carpetas en su cuenta de google drive.\n","# # Puede ver la estructura de carpetas apretando en\n","# # el icono de carpeta de la barra lateral izquierda.\n","\n","# try:\n","#     from google.colab import drive\n","#     drive.mount('/content/drive')\n","\n","#     ### Camino a carpeta de los archivos (ajustarlo segun corresponda)\n","#     dir_files = './drive/MyDrive/DSPAudio/Practico4/Archivos_P4/'\n","\n","# except:\n","#   dir_files = './Archivos_P4/'\n","\n","# print(f'Files path: {dir_files}')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"E1Yd4l1_GJR4"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import io, signal\n","from scipy.linalg import solve_toeplitz\n","from scipy.io.wavfile import read\n","from IPython.display import Audio"]},{"cell_type":"markdown","metadata":{"id":"f2YWv_3P_MJn"},"source":["# Ejercicio 1\n","\n","En este ejercicio se estudia el cepstrum de señales de audio. Según el modelo del mecanismo de producción de la voz, la señal de voz se puede expresar como $s[n]=p[n]*h[n]$, donde $p[n]$ es la señal de excitación y $h[n]$ es la respuesta al impulso del tracto vocal. Mediante el cepstrum complejo se pretende deconvolucionar la señal de voz en la excitación y la respuesta al impulso.\n","\n","\n","## Parte 1\n","\n","\n","1. En el caso de sonidos sonoros, la excitación $p[n]$ es un tren de pulsos periódico,\n","\n","    $$p[n]=\\beta^n\\sum_{k=0}^{\\infty}\\delta[n-kP]$$\n","\n","    Calcular analíticamente el cepstrum complejo $\\hat{p}[n]$ de $p[n]$. Graficar empleando los valores $\\beta = 0.99$ y $P=100$.\n","\n","1. Calcular analíticamente el cepstrum complejo $\\hat{h}[n]$ de la secuencia $h[n]$ cuya transformada $\\mathcal{Z}$ es\n","  $$ H(z) = \\frac{(1-bz)(1-b^*z)}{(1-cz^{-1})(1-c^*z^{-1})},\\;\\;\\;\\textrm{con }|b|,|c|<1 $$\n","\n","$\\qquad$ Graficar empleando los valores $b=0.98e^{j0.81\\pi}$ y $c=0.98e^{j0.19\\pi}$.\n","\n","1. Considere ahora la señal $s[n]=h[n]*p[n]$. Calcular analíticamente el cepstrum $\\hat{s}[n]$ de $s[n]$.\n","\n","1. Calcular el cepstrum complejo de las señales $p[n]$ y $h[n]$ utilizando la Transformada Discreta Fourier. Comparar con el resultado analítico y comentar los resultados.\n","\n","1. Se desea recuperar la respuesta al impulso $h[n]$ a partir de la señal $s[n]$. Para hacerlo, liftrar el cepstrum complejo $\\hat{s}[n]$ apropiadamente eliminando los componentes de altas quefrencys y aplicar el cepstrum inverso. Comparar gráficamente la respuesta al impulso recuperada con la respuesta al impulso verdadera.\n"]},{"cell_type":"markdown","metadata":{"id":"EQKPkNIy_MJq"},"source":["## Parte 2\n","Algunas aplicaciones del cepstrum real en señales de voz son la estimación de la frecuencia fundamental y la detección de formantes. Para eso, se procesa la señal en fragmentos de tiempo corto y se calcula el cepstrum real de cada fragmento. La presencia de un pico en la región de medianas o altas quefrencys es un indicador de sonoridad y la quefrency del pico indica el período.\n","\n","Se sugiere seguir los siguientes pasos para estimar la evolución de la frecuencia fundamental de la señal de voz del archivo [*tamy-vocals.wav*](./Archivos_P4/problema1/tamy-vocals.wav)\n","\n","  1. Calcular el cepstrum de tiempo corto de la señal. Graficar el resultado en el plano tiempo-quefrency eliminando los componentes de bajas quefrencys para la correcta visualización del cepstrum del tren de pulsos periódico en las regiones sonoras.\n","  1. A partir de la presencia y posición del pico construir un algoritmo para la detección de sonoridad y frecuencia fundamental. Establecer la frecuencia fundamental en 0 Hz en las regiones en donde el sonido es sordo. Comparar el resultado con el [*ground-truth*](./Archivos_P4/problema1/tamy-vocals_ground_truth.csv).\n","  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"AH53UFHT_MJt"},"source":["# Ejercicio 2\n","\n","## Parte 1\n","\n","En el modelo de predicción lineal se asume que la muestra actual de la señal de voz $s[n]$ es predecible a partir de una combinación lineal de $p$ muestras previas,\n","\n","$$\\tilde{s}[n] = \\sum_{k=1}^{p}\\alpha_k s[n-k]$$\n","\n","El problema consiste en encontrar los coeficientes $\\alpha_k$ del predictor que mejor aproximan a la señal $s[n]$. Para eso se define el error de predicción como\n","\n","$$e_n[m] = s_n[m] - \\tilde{s}_n[m]$$\n","\n","donde $s_n[m]$ es un fragmento de tiempo corto de la señal de voz elegido en torno a la muestra $n$.\n","\n","Se define el error cuadrático medio de predicción como\n","\n","$$E_n = \\sum_m e_n^2[m]$$\n","\n","para algún intervalo de muestras $m$ que no es necesario especificar por el momento. \n","En el modelo de predicción lineal, el conjunto de coeficientes $\\lbrace\\hat{\\alpha}_k\\rbrace$ óptimo es el que minimiza el error cuadrático medio de predicción. Se pide: \n","\n","\n","1. Demostrar que los coeficientes que minimizan el error cuadrático medio obedecen el siguiente sistema lineal de ecuaciones (*ecuaciones normales*),\n","\n","    $$\\sum_{k=1}^{p}\\hat{\\alpha}_k\\sum_m s_n[m-i]s_n[m-k]=\\sum_m s_n[m-i]s_n[m],\\,\\,\\,1\\leq i \\leq p$$\n","\n","1. Demostrar que el error cuadrático medio mínimo de predicción es\n","\n","    $$E_n = \\sum_m s_n^2[m]-\\sum_{k=1}^p\\hat{\\alpha}_k\\sum_m s_n[m]s_n[m-k]$$\n"]},{"cell_type":"markdown","metadata":{"id":"1eOz3MfF_MJv"},"source":["\n","## Parte 2\n","\n","En este problema se aplica la técnica de LPC para la clasificación de vocales, usando una base de datos de vocales aisladas pronunciadas por dos hablantes.\n","\n","El procedimiento consiste en calcular el modelo todo polos de la señal de voz, y a partir de los polos obtener la frecuencia de las dos primeras formantes $\\left(F_1,\\,F_2\\right)$. \n","\n","\n","A modo de referencia, en el cuadro de abajo se indica la frecuencia promedio de las dos primeras formantes de las vocales del idioma español (Estos datos son aproximaciones de los datos provistos en https://joaquimllisterri.cat/phonetics/fon_anal_acus/caract_acust.html). \n","\n","\n","La señal analizada puede clasificarse a partir la vocal de referencia mas cercana en el plano $\\left(F_1,\\,F_2\\right)$.\n","\n","| Fonema | $F_1(Hz)$ | $F_2(Hz)$ |\n","|:------:|:---------:|:---------:|\n","|   /a/  |    800    |    1170   |\n","|   /e/  |    480    |    2300   |\n","|   /i/  |    240    |    2800   |\n","|   /o/  |    510    |    960    |\n","|   /u/  |    250    |    630    |\n","\n","<center>**Primeras dos formantes de las vocales en el idioma español.**</center>\n","\n","\n","1. Implementar un algoritmo para procesar todas las señales de la base de datos, calculando para cada una la frecuencia de las dos primeras formantes. Mostrar los resultados como un mapa de formantes en el plano $\\left(F_1,\\,F_2\\right)$.\n","1. Clasificar las señales a partir de las vocales de referencia. Reportar la tasa de acierto obtenida para cada vocal y para cada hablante.\n","1. Analizar los resultados y proponer alguna estrategia para mejorarlos. \n","    \n","\n","Las señales de la base de datos están muestreadas a 8000 Hz. Hay un directorio por hablante y el nombre de los archivo de audio es **[vocal]-[número].wav**, con **número** de 1 a 10. \n","Los archivos contienen un único fonema, de duración variable (sin silencio al comienzo o al final), pero todos superan las 550 muestras.\n","\n","\n","Tener en cuenta los siguientes aspectos. \n","\n","- Se sugiere tomar una ventana centrada en la muestra central de cada señal. \n","- Elegir adecuadamente el tamaño de la ventana $N$ y el orden $p$ del modelo.\n","- Calcular los polos y representarlos en un diagrama de polos y ceros. \n","- Eliminar los polos reales y los polos con $\\omega\\geq\\pi$ (Son redundantes por ser complejos conjugados de los polos con $\\omega<\\pi$). Eliminar los polos de ancho de banda mayor a cierto umbral. Elegir adecuadamente el umbral.\n","- Establecer la frecuencia de las dos primeras formantes como la frecuencia de los dos polos de menor frecuencia.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wO1ODq2Zlh01"},"outputs":[],"source":["### Cargar los audios y asignarle una etiqueta del tipo #hablante-vocal\n","vocales = ['a','e','i','o','u']\n","folders = ['/problema2/vocales/martin/','/problema2/vocales/cecilia/']\n","indices = np.arange(1,11)\n","\n","files_list = []\n","labels = []\n","\n","for folder in folders:\n","  for vocal in vocales:\n","    for indice in indices:\n","      _, audio = io.wavfile.read(dir_files + folder + vocal + '-' + str(indice) + '.wav')\n","      files_list.append(audio)\n","      labels.append(str(folders.index(folder)) + '-' + vocal)\n","      \n","# Frecuencia de muestreo\n","fs = 8000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1667320004363,"user":{"displayName":"Emilio Martinez","userId":"13206038817953278252"},"user_tz":180},"id":"whQB85B8oGEF","outputId":"c08d1660-34af-4993-a016-f4707c2827af"},"outputs":[],"source":["# Escuchar vocal del hablante 1\n","Audio(files_list[45], rate=fs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1667320004365,"user":{"displayName":"Emilio Martinez","userId":"13206038817953278252"},"user_tz":180},"id":"KJ-Q2L_rrR56","outputId":"daa30674-f3dc-48d6-f96a-e888719e8dd3"},"outputs":[],"source":["# Escuchar vocal del hablante 2\n","Audio(files_list[95], rate=fs)"]}],"metadata":{"colab":{"collapsed_sections":["f2YWv_3P_MJn"],"provenance":[{"file_id":"https://github.com/mrocamora/audio-dsp/blob/main/practicos/AudioDSP_Practico_4.ipynb","timestamp":1654048763245}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}
