{"cells":[{"cell_type":"markdown","metadata":{"id":"9R66vy-1Fn5C"},"source":["\n","### <center>Procesamiento Digital de Señales de Audio</center>\n","#### <center>Instituto de Ingeniería Eléctrica - UdelaR</center>\n","# Hoja de Ejercicios 3 - Curso 2024\n","## Análisis de Fourier de tiempo corto\n","### Procesamiento tiempo-frecuencia\n","\n","\n","## Pautas para el práctico\n"," - La realización del presente trabajo es individual.\n"," - Es necesario abordar todos los ejercicios propuestos.\n"," - Se espera la entrega de un PDF escrito en $\\LaTeX$ o similar. El mismo tendrá:\n","     - Máximo de 14 páginas\n","     - Máximo de 2500 palabras\n"," - También se espera la entrega del código escrito, en scripts Python o en este mismo Jupyter Notebook.\n"," - La corrección del práctico se hará sobre lo entregado en el PDF, pero podremos apoyarnos en el razonamiento y comprensión demostrado en el código escrito. Recomendamos escribir el código de forma prolija para facilitar la comprensión presente y futura tanto de nosotros como de ustedes.\n"," - Los ejercicios marcados como $\\blacklozenge$ son opcionales.\n","\n","\n","**Nombre de el/la estudiante:** "]},{"cell_type":"markdown","metadata":{"id":"YYZZmEsGhHcG"},"source":["### Cómo correr este notebook\n","\n","Es posible descargarlo y correrlo localmente en su computadora\n","\n","Tambien pueden correrlo en Google Colab usando el siguiente link.\n","\n","<table align=\"center\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/audio-dsp/blob/main/practicos/AudioDSP_Practico_3.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Correr en Google Colab</a>\n","  </td>\n","</table>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20495,"status":"ok","timestamp":1653926491589,"user":{"displayName":"Emilio Martinez","userId":"13206038817953278252"},"user_tz":180},"id":"MdUJ8uyXij2V","outputId":"04d3d205-27e0-47f5-8943-344895ad0e95","scrolled":true},"outputs":[],"source":["# Al correr esta celda, se podrá acceder a archivos\n","# y carpetas en su cuenta de google drive.\n","# Puede ver la estructura de carpetas apretando en\n","# el icono de carpeta de la barra lateral izquierda.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Directorio de archivos\n","dir_files = './Archivos_P3/'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":730,"status":"ok","timestamp":1653926500310,"user":{"displayName":"Emilio Martinez","userId":"13206038817953278252"},"user_tz":180},"id":"E1Yd4l1_GJR4"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import io, signal\n","import pandas as pd\n","from scipy.io.wavfile import read\n","from IPython.display import Audio"]},{"cell_type":"markdown","metadata":{"id":"yTvHWpQYhHcL"},"source":["# Ejercicio 1\n","\n","En este ejercicio se estudia la relación entre la transformada de Fourier de tiempo corto y la función de autocorrelación de tiempo corto. Si definimos la densidad espectral de potencia en tiempo corto de una señal ($x[n]$) en función de su transformada de Fourier en tiempo corto como\n","\n","\\begin{equation*}\n","\tS_n(e^{jw}) = |X_n(e^{jw})|^2\n","\\end{equation*}\n","\n","y la función de autocorrelación de tiempo corto de la señal ($x[n]$) como\n","\n","\\begin{equation*}\n","\tR_n[k] = \\sum_{m=-\\infty}^{\\infty}w[n-m]x[m]w[n-k-m]x[m+k],\n","\\end{equation*}\n","\n","probar que si\n","\n","\\begin{equation*}\n","\tX_n(e^{jw}) = \\sum_{m=-\\infty}^{\\infty}x[m]w[n-m]e^{-jwm}\n","\\end{equation*}\n","\n","$R_n[k]$ y $S_n(e^{jw})$ son un par de transformadas, i.e. $S_n(e^{jw})$ es la transformada de Fourier de $R_n[k]$.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruTnxuNuhHcM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"T4MyZTCyhHcN"},"source":["# Ejercicio 2\n","\n","En este ejercicio se estudia un método de detección de frecuencia fundamental (o _pitch_) basado en la transformada de Fourier de tiempo corto. Se sugiere utilizar el archivo [_LP-mem-6-a.wav_](./Archivos_P3/LP-mem-6-a.wav) para probarlo.\n","\n","## Parte 1\n","El producto armónico espectral -Harmonic Product Spectrum, HPS- (ver _Pitch Detection in the Spectral Domain, pág. 623_, en  L. R. Rabiner and R. W. Schafer, _Theory and Applications of Digital Speech Processing_. Prentice Hall, 1st ed., 2011 [1]) está dado por\n","\n","\\begin{equation*}\n","\tP_n(e^{jw}) = \\prod_{r=1}^{K}|X_n(e^{jwr})|^2\n","\\end{equation*}\n","\n","Tomando el logaritmo se obtiene (log-Harmonic Product Spectrum, log-HPS),\n","\n","\\begin{equation*}\n","\t\\hat{P}_n(e^{jw}) = 2\\sum_{r=1}^{K}\\log|X_n(e^{jwr})|\n","\\end{equation*}\n","\n","**_Responder:_**\n","\n","Explique por qué el HPS puede usarse para detección de _pitch_. Asuma que la señal de audio es monofónica (una única fuente armónica). ¿Qué ventajas presenta el uso del log-HPS frente al HPS? ¿Qué ocurre con señales cuya frecuencia fundamental está ausente (e.g. filtrado pasa-altos por el canal de comunicación)?\n"]},{"cell_type":"markdown","metadata":{},"source":["_Respuesta:_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTKAdSNLhHcP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"QpJf4BshhHcP"},"source":["## Parte 2\n","\n","El espectro logarítmico acumulado (ó GLogS por sus siglas en inglés), se calcula como el promedio de logaritmo de la magnitud del espectro en posiciones armónicas de una frecuencia fundamental $f_0$, como\n","\n","\\begin{equation*}\n","\t\\rho_n(f_0) = \\frac{1}{n_H}\\sum_{i=1}^{n_H}\\log|X_n(if_0)|\n","\\end{equation*}\n","\n","siendo $n_H$ la cantidad de armónicos de $f_0$ cuya frecuencia es menor a cierta frecuencia máxima $f_{\\max}$.\n","\n","Implemente un algoritmo de detección de _pitch_ que calcule el GLogS para valores de $f_0$ distribuidos de forma logarítmica entre $55Hz$ ($A1$) y $1046.5Hz$ ($C6$) con un paso de cuarto de tono, y $f_{\\max} =  5000Hz$."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Implementación"]},{"cell_type":"markdown","metadata":{"id":"0AKgJUPthHcS"},"source":["## Parte 3\n","\n","1. Utilice el GLogS para obtener una representación tiempo-$f_0$, que denominaremos $f_0$-grama. Compare dicha representación con el espectrograma usando el archivo de audio [_LP-mem-6-a.wav_](./Archivos_P3/LP-mem-6-a.wav).\n","\n","2. **Responder:** ¿por qué tiene sentido utilizar $f_{max} = 5000~Hz$?\n","\n","$\\qquad$ _Nota:_ Puede ser de utilidad observar el espectrograma completo.\n","\n","3. Represente la frecuencia fundamental detectada y la frecuencia de referencia en el $f_0$-grama en el archivo [_LP-mem-6-a.txt_](./Archivos_P3/LP-mem-6-a.txt). **Comente si aparecen los errores de armónicos y por qué**."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{"id":"2qe5EAaPhHcT"},"source":["# Ejercicio 3\n","\n","En este ejercicio teórico, recordamos la condición la síntesis de la STFT discreta mediante el método Overlap-Add (OLA), de que la suma de las ventanas en el tiempo debe ser igual a una constante, y buscaremos probar que esto se cumple bajo ciertas condiciones para el caso de las ventanas de Hann. \n","\n","Las ventanas de Hann, comúnmente usadas en análisis y síntesis mediante OLA, se definen para el caso de una ventana de largo 2M+1 de la manera siguiente:\n","\n","\\begin{equation*}\n","    w_{Hann}[n]=[0.5 + 0.5cos(\\pi n/M)]w_r[n]\n","\\end{equation*}\n","\n","donde $w_r[n]$ es una ventana rectangular que representa el requerimiento de the $w_{Hann}[n]=0$ cuando $|n|>M$. Esta ventana podría ser de la forma\n","\n","\\begin{equation*}\n","    w_r[n]=\n","            \\begin{cases}\n","                1, & -M \\leq n \\leq M-1 \\\\\n","                0, & \\text{en otro caso}.\n","            \\end{cases}\n","\\end{equation*}\n","\n","## Parte 1\n","Mostrar que la DTFT de $w_r[n]$ es\n","\n","\\begin{equation*}\n","    W_r(e^{j\\omega}) = \\bigg(\\frac{1-e^{-j\\omega 2M}}{1-e^{-j\\omega}}\\bigg)e^{j\\omega M}\n","\\end{equation*}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sn44JgzoG7Zb"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"UUkPZ300hHcV"},"source":["## Parte 2\n","**Mostrar que**\n","\n","\\begin{equation*}\n","    W_{Hann}(e^{j\\omega}) = 0.5W_r(e^{j\\omega}) +0.25 W_r(e^{j(\\omega-\\pi/M)})+0.25 W_r(e^{j(\\omega+\\pi/M)})\n","\\end{equation*}\n","\n","*Nota:* puede ser de utilidad representar la función $\\cos (\\pi n /M)$ de $w_{Hann}[n]$ en su formulación de exponenciales complejas.\n","\n","-------------\n","\n","Es posible probar, utilizando el resultado de la parte anterior, que $W_{Hann}(e^{j\\omega})$ depende solamente de $\\omega$ y $M$, **resultando en la siguiente expresión**:\n","\n","\\begin{align*}\n","W_{Hann}(e^{j\\omega}) &= 2j\\sin(\\omega M) \\left[ \\frac{1}{2} \\left( \\frac{1}{1-e^{-j\\omega}} \\right) - \\frac{1}{4} \\left( \\frac{1}{1-e^{-j(\\omega-\\pi /M)}}\\right) - \\frac{1}{4} \\left( \\frac{1}{1-e^{-j(\\omega+\\pi /M)}}\\right) \\right]\n","\\end{align*}\n","\n","No es necesario demostrar cómo se llega a esta expresión ($\\blacklozenge$), pero será de utilidad este resultado para continuar con las siguientes partes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwMugZeWhHcV"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"3VqVEQUfhHcW"},"source":["## Parte 3\n","Usar los resultados de las partes anteriores para demostrar que $W_{Hann}(e^{j\\omega_k}) = 0$ para todo $k=1,2,...,M-1$ (con $\\omega_k=\\frac{2\\pi k}{M}$) y por lo tanto es posible una reconstrucción perfecta si $R=M$ o $R=M/2$ (si $M/2$ es un entero), siendo $R$ el período de muestreo (en muestras) en el tiempo de la STFT. Ver cap 7.5 en [1].\n","\n","_Sugerencia:_ notar que la reconstrucción perfecta con OLA implica la siguiente igualdad:\n","$$\n","y[n] = x[n]\\left( \\sum_{r=-\\infty}^{+\\infty} w_{Hann}[rR-n] \\right) = x[n],\n","$$\n","\n","$\\qquad$ donde $x[n]$ es la señal a analizar e $y[n]$ la re-síntesis/reconstrucción."]},{"cell_type":"markdown","metadata":{"id":"SMRwMNUohHcW"},"source":["## Parte 4\n","Usar los resultados de las partes 1 y 2 para mostrar que $W_{Hann}(e^{j0}) = M$ y por lo tanto la ganancia de reconstrucción es $C=M/R$"]},{"cell_type":"markdown","metadata":{"id":"B53KX-LchHcX"},"source":["# Ejercicio 4\n","\n","En este ejercicio se implementa la técnica de phase-vocoder y se la utiliza para generar transformaciones de la señal de audio. Se sugiere utilizar el archivo [_singing\\_voice.wav_](./Archivos_P3/singing_voice.wav) ó [_guitar\\_lick.wav_](./Archivos_P3/guitar_lick.wav) para probarla.\n","\n","En la etapa de análisis se calcula la transformada de Fourier de tiempo corto, como \n","\n","\\begin{equation*}\n","    X_{n_a^u}(e^{j\\omega_k})=\\sum_{m=-\\infty}^{\\infty}w_a[n_a^u-m]\\, x[m]\\, e^{-j\\omega_kn}\n","\\end{equation*}\n","\n","en donde, $w_a[n]$ es la ventana de análisis, $\\omega_k=\\frac{2\\pi}{N} k$, con \\(N\\) la cantidad de puntos de la DFT, y $n_a^u = u \\, R_a$, con $R_a$ el hop de análisis en muestras y $u$ el índice de la trama temporal, de valor inicial 0.\n","\n","En la etapa de síntesis se reconstruye la señal en el dominio del tiempo mediante la antitransformada de Fourier de cada trama temporal y el procedimiento de solapamiento y suma (overlap-add), como \n","\n","\\begin{equation*}\n","    y[n]=\\sum_{u=-\\infty}^{\\infty}w_s[n-n_s^u]y_u[n-n_s^u]\n","\\end{equation*}\n","\n","con\n","\n","\\begin{equation*}\n","    y_u[n]=\\frac{1}{N}\\sum_{k=0}^{N-1}Y_{n_s^u}(e^{j\\omega_k}) \\, e^{j\\omega_kn}\n","\\end{equation*}\n","\n","en donde, $w_s[n]$ es la ventana de síntesis, y $n_s^u=u \\, R_s$, siendo $R_s$ el hop de síntesis en muestras. Notar que $y_u[n]$ es la transformada inversa de Fourier de una trama de la STFT. Cuando no hay modificaciones entre la etapa de análisis y síntesis, $Y_{n_s^u}(e^{j\\omega_k}) = X_{n_a^u}(e^{j\\omega_k})$ y $R_s = R_a$. En ese caso la ventana de síntesis $w_s[n]$ es opcional, pero se hace importante si se aplican modificaciones, por ejemplo cuando $R_s \\neq R_a$.  \n","  \n","## Parte 1\n","\n","Implemente el análisis y la síntesis para $Y_{n_s^u}(e^{j\\omega_k})=X_{n_a^u}(e^{j\\omega_k})$ y $R_s=R_a$. Elija un valor de $R_a$ para tener reconstrucción perfecta con ventana de Hann y verifique experimentalmente. Justifique su elección."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":638,"status":"ok","timestamp":1653953429921,"user":{"displayName":"Emilio Martinez","userId":"13206038817953278252"},"user_tz":180},"id":"GEIdROJiqcu8"},"outputs":[],"source":["# fs, x = io.wavfile.read(dir_files+'singing_voice.wav')\n","fs, x = io.wavfile.read(dir_files+'guitar_lick.wav')\n","Audio(x, rate=fs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"S6Xuk9r1hHcY"},"source":["## Parte 2\n","\n","Realice modificaciones de la escala temporal usando $R_s \\neq R_a$. En particular pruebe duplicando y reduciendo a la mitad la duración original. Analice los resultados obtenidos y los artefactos que se introducen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"9MvcR0kEhHcZ"},"source":["## Parte 3\n","\n","Para evitar la mayoría de los problemas introducidos debido a la inconsistencia de fase, se sugiere utilizar el procedimiento de desdoblamiento de fase (phase unwrapping). \n","\n","Asumiendo que existe un solo componente sinusoidal por bin de la DFT, podemos plantear las siguientes ecuaciones para estimar la fase de $Y_{n_s^u}(e^{j\\omega_k})$, cuando transformamos la escala temporal utilizando un hop de síntesis $R_s \\neq R_a$. \n","\n","Se calcula el incremento de fase heterodino, a partir del incremento de fase de tramas sucesivas \n","\n","\\begin{equation*}\n","    \\Delta\\Phi_k^u=\\angle X_{n_a^u}(e^{j\\omega_k}) - \\angle X_{n_a^{u-1}}(e^{j\\omega_k}) - R_a \\, \\omega_k\n","\\end{equation*}\n","\n","Notar que el término $R_a\\ \\omega_k$ es el incremento de fase que cabría esperar si la frecuencia del componente sinusoidal correspondiera exactamente a la frecuencia de análisis. \n","\n","Se toma el argumento principal de $\\Delta\\Phi_k^u$ entre ($-\\pi, \\pi$), que denominamos $\\Delta_p\\Phi_k^u$. \n","\n","Luego se calcula la estimación de la frecuencia instantánea\n","\n","\\begin{equation*}\n","    \\hat{\\omega}_k[{n^u_a}] = \\omega_k + \\frac{1}{R_a} \\, \\Delta_p\\Phi_k^u\n","\\end{equation*}\n","\n","Finalmente se calcula la fase de $Y_{n_s^u}(e^{j\\omega_k})$ utilizando la fórmula de propagación de fase\n","\n","\\begin{equation*}\n","    \\angle Y_{n_s^u}(e^{j\\omega_k}) = \\angle Y_{n_s^{u-1}}(e^{j\\omega_k}) + R_s \\, \\hat{\\omega}_k[{n^u_a}]\n","\\end{equation*}\n","\n","Notar que de acuerdo a la fórmula anterior se hace necesario acumular la fase de tramas sucesivas y establecer un valor para la fase inicial (se sugiere considerar $\\angle Y_{n_s^{0}}(e^{j\\omega_k}) = \\angle X_{n_a^{0}}(e^{j\\omega_k})$). Cabe señalar que es importante aplicar una ventana de suavizado $w_s[n]$ en la síntesis. Se sugiere utilizar ventanas de Hann con $w_a[n] = w_s[n]$. Tenga en cuenta que esto modifica el factor de escalamiento temporal. Para profundizar en el estudio de este procedimiento y otras consideraciones sobre la fase se recomienda [2,3].\n","\n","\n","Implemente el desdoblamiento de fase y compare los resultados con los obtenidos en la parte anterior. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"N57kgUF4hHca"},"source":["## Parte 4\n","\n","Usando el phase-vocoder implemente las siguientes transformaciones de la señal de audio. Además de implementar **1)**, hacer _por lo menos_ una de las opciones **2)** y **3)**.\n","\n","**_Nota:_** incluya en el informe los espectrogramas de las señales generadas y entregue también las señales de audio.\n","\n"," 1. **Transposición en frecuencia (pitch-shifting)**: Se desea una señal de la misma duración que la señal original, pero alterando su contenido espectral. Para ello deben realizarse dos acciones complementarias: un escalamiento en el tiempo y un cambio en la frecuencia de muestreo. Por ejemplo, si se desea subir/bajar el contenido espectral de la señal un semitono, se debe aumentar/disminuir la duración de la señal por un factor de $2^{\\frac{1}{12}}$, y luego aumentar/disminuir la frecuencia de muestreo por el mismo factor, de modo de obtener una señal de la misma duración que la original.\n"," \n","_Elegir:_\n","\n"," 2. **Armonizador**: Utilizando el efecto de transposición en frecuencia sumar a la señal original una versión desplazada una quinta (factor de $2^{\\frac{7}{12}}\\simeq\\frac{3}{2}$).\n"," \n"," $\\qquad$ y/ó\n","\n"," 3. **Coro (_chorus_)**: Consiste en simular que la señal de voz de un único interprete es entonada por varias voces cantando al unísono (es una variación del efecto de armonización). Se deben superponer varias señales con pequeñas modificaciones de _pitch_ respecto al de la señal original y ligeramente distinto para cada uno. El cambio no debe ser mayor que un cuarto de semitono (factor de $2^{\\frac{1}{48}}$)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["------"]},{"cell_type":"markdown","metadata":{"id":"LWPP6vu5hHca"},"source":["# Referencias\n","\n","[1] L. R. Rabiner and R. W. Schafer, *Theory and Applications of Digital Speech Processing*. Prentice\n","Hall, 1st ed., 2011.\n","\n","[2] J. Laroche and M. Dolson, “Improved phase vocoder time-scale modification of audio,” *IEEE Transac-\n","tions on Speech and Audio processing*, vol. 7, no. 3, pp. 323–332, 1999.\n","\n","[3] A. Gotzen, N. Bernardin, and D. Arfib., “Traditional implementations of a phase-vocoder: The tricks\n","of the trade,” in *International Conference on Digital Audio Effects, Italy*, Dec. 2000"]},{"cell_type":"markdown","metadata":{"id":"nUpPlsAqhHcb"},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXCEo-1ShHcb"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["9R66vy-1Fn5C"],"name":"AudioDSP - Practico 3.ipynb","provenance":[{"file_id":"https://github.com/mrocamora/audio-dsp/blob/main/practicos/AudioDSP_Practico_3.ipynb","timestamp":1652212150484}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
